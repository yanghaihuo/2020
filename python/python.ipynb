{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本去噪\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "inputfileq0 = 'q_0.txt' #评论提取后保存路径\n",
    "outputfileq1 = 'q_1.txt' #评论处理后保存路径\n",
    "data = pd.read_csv(inputfileq0, encoding = 'utf-8', header = None)\n",
    "filelist =  list(data[0])\n",
    "filelist2 = []\n",
    "r='[\\s+\\.!\\/_,$%^*(+\\\"\\')]+|[:：+——()?【】“”！，。？、~@#￥%……&*（）]+'\n",
    "r1='[^\\u4e00-\\u9fa5]'\n",
    "for a_string in filelist:\n",
    "    a_string=str(a_string)\n",
    "    temp = re.sub(r,'',a_string)   #删除标点符号\n",
    "    temp = re.sub(r1,'',temp)   #删除英文和数字\n",
    "    filelist2.append(temp)\n",
    "filelist3 =  pd.DataFrame(filelist2)\n",
    "filelist3.to_csv(outputfileq1, index = False, header = False, encoding = 'utf-8')\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('order.xlsx', parse_dates=['ts'])\n",
    "data['current_dt']=pd.datetime.now()\n",
    "data['current_dt']=data['current_dt'].apply(lambda x: x.strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "data['current_dt'] = pd.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data['dt_ts'] = pd.to_datetime(data['str_ts'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data['dt_day'] = data['ts'].dt.date#提取年月日\n",
    "data['year'] = data['ts'].dt.year#提取年份\n",
    "data['month'] = data['ts'].dt.month#提取月份\n",
    "data['day'] = data['ts'].dt.day#提取天数\n",
    "data['dt_time'] = data['ts'].dt.time#提取时间\n",
    "data['hour'] = data['ts'].dt.hour#提取小时\n",
    "data['minute'] = data['ts'].dt.minute#提取分钟\n",
    "data['second'] = data['ts'].dt.second#提取秒\n",
    "\n",
    "\n",
    "# 可读日期转换为unix时间戳\n",
    "#python\n",
    "def transfer_time_format(x):\n",
    "    import time\n",
    "    tmp_time = time.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    res_time = int(time.mktime(tmp_time))\n",
    "    return res_time\n",
    "\n",
    "data['str_ts'] = data['ts'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "data['str_timestamp'] = data['str_ts'].apply(transfer_time_format)\n",
    "data.head()\n",
    "#使用匿名函数的写法\n",
    "#data['str_timestamp'] = data['str_ts'].apply(lambda x: int(time.mktime(time.strptime(x, '%Y-%m-%d %H:%M:%S'))))\n",
    "\n",
    "# unix时间戳转换为可读日期\n",
    "#pandas:\n",
    "def transfer_time_format2(x):\n",
    "    import time\n",
    "    time_local = time.localtime(x)\n",
    "    res_time = time.strftime('%Y-%m-%d %H:%M:%S', time_local)\n",
    "    return res_time\n",
    "data['ori_ts'] = data['str_timestamp'].apply(transfer_time_format2)\n",
    "data.head()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "# 一键对多个值演示方法1：\n",
    "d = {}\n",
    "lst = [(1,'apple'),(2,'orange'),(1,'compute')]\n",
    "for k,v in lst:\n",
    "    if k not in d:\n",
    "        d[k]=[]\n",
    "    d[k].append(v)\n",
    "\n",
    "print(d) # {1: ['apple', 'compute'], 2: ['orange']}\n",
    "\n",
    "# 方法2，建议使用defaultdict\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "for k,v in lst:\n",
    "    d[k].append(v)\n",
    "\n",
    "print(d) # defaultdict(<class 'list'>, {1: ['apple', 'compute'], 2: ['orange']})\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.__version__\n",
    "\n",
    "dates = pd.date_range('today',periods=6) # 定义时间序列作为 index\n",
    "num_arr = np.random.randn(6,4) # 传入 numpy 随机数组\n",
    "columns = ['A','B','C','D'] # 将列表作为列名\n",
    "df = pd.DataFrame(num_arr, index = dates, columns = columns)\n",
    "\n",
    "df[df['age'].between(2, 4)]\n",
    "df.loc['f', 'age'] = 1.5\n",
    "\n",
    "df.pivot_table(index='animal', columns='visits', values='age', aggfunc='mean')\n",
    "\n",
    "print(f\"姓名:{stu['name']}, 年龄:{stu['age']}, 性别:{stu['gender']}\")\n",
    "\n",
    "# 把时间差转换为带小数以小时为单位的数字\n",
    "df['工单处理时长']=(df['完成时间']-df['派单时间'])/np.timedelta64(1,'h')  # M：月  D:天 \n",
    "      \n",
    "***********************************************************************************************************************************\n",
    "# 给定DataFrame，求A列每个值的前3和后3的B的值的和\n",
    "df = pd.DataFrame({'A': list('aaabbcaabcccbbc'),\n",
    "                   'B': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "df1 = df.groupby('A')['B'].nlargest(3).sum(level=0)\n",
    "df2 = df.groupby('A')['B'].nsmallest(3).sum(level=0)\n",
    "***********************************************************************************************************************************\n",
    "# 给定DataFrame，有列A, B，A的值在1-100（含），对A列每10步长，求对应的B的和\n",
    "df = pd.DataFrame({'A': [1,2,11,11,33,34,35,40,79,99],\n",
    "                   'B': [1,2,11,11,33,34,35,40,79,99]})\n",
    "df1 = df.groupby(pd.cut(df['A'], np.arange(0, 101, 10)))['B'].sum()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "# Airline列，有一些多余的标点符号，需要提取出正确的航司名称。举例：'(British Airways. )' 应该改为 'British Airways'.\n",
    "df['Airline'] = df['Airline'].str.extract('([a-zA-Z\\s]+)').str.strip()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "\n",
    "m=pd.DataFrame({'a':[25,36,25,36,89,38,96,36,38,25]})\n",
    "# 第一种\n",
    "m.a.value_counts().reset_index().rename(columns={\"index\":'a','a':\"counts\"})\n",
    "# 第二种\n",
    "m.groupby(m['a']).size().to_frame('count').reset_index()\n",
    "\n",
    "# 第三种\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\abc.csv')\n",
    "df2 = df['name'].value_counts()\n",
    "df2.index\n",
    "df2.to_csv(r'D:/abc2.csv', index=True, index_label='name', header=['count'])\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "data.insert(0, '性别', data.pop('gender')) #pop返回删除的列，插入到第0列，并取新名为'性别'\n",
    "\n",
    "proportion = proportion.applymap(lambda x: 2-2/x if x>2 else (-1 if x<-1 else x))\n",
    "prop_.to_excel(f'E:\\综合发展指数\\市州\\市州-底层指标变化情况{time.strftime(\"%Y%m%d%H%M%S\")}.xlsx')\n",
    "               \n",
    "df2['DT'].str.split(' ')\n",
    "# 将From_To列从_分开，分成From, To两列\n",
    "temp = df.From_To.str.split('_', expand=True)\n",
    "temp.columns = ['From', 'To']\n",
    "               \n",
    "# assign是直接向DataFrame对象添加新的一列               \n",
    "df = pd.concat([train.assign(is_train=1), test.assign(is_train=0)])               \n",
    "               \n",
    "               \n",
    "# 分别取0到2行，2到4行，4到9行组成一个列表，通过concat方法按照axis=0，行方向合并, axis参数不指定，默认为0\n",
    "split_rows = [df.iloc[0:2,:],df.iloc[2:4,:], df.iloc[4:9]]\n",
    "pd.concat(split_rows)\n",
    "               \n",
    "df = pd.read_csv(\"stock.csv\", index_col=0, dtype={\"Code\": str})\n",
    "               \n",
    "dtype_dict = {'buyer_admin_id' : 'int32', \n",
    "              'item_id' : 'int32', \n",
    "              'store_id' : pd.Int32Dtype(),\n",
    "              'irank' : 'int16',\n",
    "              'item_price' : pd.Int16Dtype(),\n",
    "              'cate_id' : pd.Int16Dtype(),\n",
    "              'is_train' : 'int8',\n",
    "              'day' : 'int8',\n",
    "              'hour' : 'int8'}\n",
    "df = df.astype(dtype_dict)               \n",
    "***********************************************************************************************************************************\n",
    "# 给字典排序\n",
    "d={'a':1,'c':3,'b':2}   \n",
    "d_result=sorted(d.items(),key=lambda x:x[1],reverse=False) \n",
    "\n",
    "\n",
    "d={'a':1,'c':3,'b':2}   \n",
    "L=list(d.items())       \n",
    "L.sort(key=lambda x:x[1],reverse=False)  \n",
    "\n",
    "# 给列表中的多个字典键降序排序\n",
    "rows = [\n",
    "    {'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},\n",
    "    {'fname': 'David', 'lname': 'Beazley', 'uid': 1002},\n",
    "    {'fname': 'John', 'lname': 'Cleese', 'uid': 1001},\n",
    "    {'fname': 'Big', 'lname': 'Jones', 'uid': 1004}\n",
    "]\n",
    "from operator import itemgetter\n",
    "rows_by_fname = sorted(rows, key=itemgetter('fname'),reverse=True)\n",
    "rows_by_uid = sorted(rows, key=itemgetter('uid'),reverse=True)\n",
    "print(rows_by_fname)\n",
    "print(rows_by_uid)\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import math\n",
    "a = float('inf')\n",
    "math.isinf(a)\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "def lower_all_string(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.lower()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "data.applymap(lower_all_string)               \n",
    "\n",
    "               \n",
    "import numpy as np\n",
    "\n",
    "def find_most_name(df):\n",
    "    return str(np.max(df['count']))+'-'+df['name'][np.argmax(df['count'])]\n",
    "\n",
    "data.groupby(['year','gender']).apply(find_most_name).reset_index(drop=False)\n",
    "\n",
    "\n",
    "# 利用agg()进行更灵活的聚合\n",
    "# 1.聚合Series\n",
    "#求count列的最小值、最大值以及中位数\n",
    "data['count'].agg(['min','max','median'])\n",
    "\n",
    "# 2.聚合数据框\n",
    "data.agg({'year': ['max','min'], 'count': ['mean','std']})\n",
    "\n",
    "# 3.聚合groupby()结果\n",
    "data.groupby(['year','gender']).agg({'count':['min','max','median']}).reset_index(drop=False)\n",
    "\n",
    "data.groupby(['year','gender']).agg(\n",
    "    min_count=pd.NamedAgg(column='count', aggfunc='min'),\n",
    "    max_count=pd.NamedAgg(column='count', aggfunc='max'),\n",
    "    median=pd.NamedAgg(column='count', aggfunc='median')).reset_index(drop=False)\n",
    "\n",
    "# 如果periods为正，则表示向下/右偏移，如果peeriods为负，则表示向上/左偏移\n",
    "df.shift(periods=1, freq=None, axis=0)\n",
    "df[\"last_sales\"] = df.groupby(\"uid\")[\"sales\"].shift(1).fillna(0)\n",
    "\n",
    "\n",
    "login_data = pd.read_csv('login_data.txt', sep='\\t', parse_dates=['ts'])\n",
    "merge_one_day['one_remain_rate'] = merge_one_day['one_remain_rate'].apply(lambda x: format(x, '.2%'))\n",
    "\n",
    "***********************************************************************************************************************************               \n",
    "# 多个嵌套列表展平\n",
    "from collections import Iterable\n",
    "\n",
    "def flatten(items, ignore_types=(str, bytes)):\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, ignore_types):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "items = [1, 2, [3, 4, [5, 6], 7], 8]\n",
    "# Produces 1 2 3 4 5 6 7 8\n",
    "for x in flatten(items):\n",
    "    print(x)\n",
    "               \n",
    "***********************************************************************************************************************************\n",
    "# 按顺序去掉重复值\n",
    "def dedupe(items):\n",
    "    seen = set()\n",
    "    for item in items:\n",
    "        if item not in seen:\n",
    "            yield item\n",
    "            seen.add(item)\n",
    "a = [1, 5, 2, 1, 9, 1, 5, 10]\n",
    "list(dedupe(a))\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "words = [\n",
    "    'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',\n",
    "    'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the',\n",
    "    'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into',\n",
    "    'my', 'eyes', \"you're\", 'under'\n",
    "]\n",
    "from collections import Counter\n",
    "word_counts = Counter(words)\n",
    "# 出现频率最高的3个单词\n",
    "top_three = word_counts.most_common(3)\n",
    "# Outputs [('eyes', 8), ('the', 5), ('look', 4)]\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "with TemporaryFile('w+t') as f:\n",
    "    # Read/write to the file\n",
    "    f.write('Hello World\\n')\n",
    "    f.write('Testing\\n')\n",
    "    # Seek back to beginning and read the data\n",
    "    f.seek(0)\n",
    "    data = f.read()\n",
    "    \n",
    "# Temporary file is destroyed\n",
    "data\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import re\n",
    "\n",
    "while 1:\n",
    "    password = input(\"请输入密码：\")\n",
    "    result = re.match(\"^[A-Za-z0-9]{6,20}$\", password)\n",
    "    if result:\n",
    "        print(\"密码符合规范\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"密码不符合规范\")\n",
    "        \n",
    "***********************************************************************************************************************************\n",
    "import datetime\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "import time\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "print(time.strftime(\"%Y%m%d%H%M%S\"))\n",
    "               \n",
    "print('*'*20)\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "mpl.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    " \n",
    "#画factorData，xstickslabel的名字保存于xaxislabel。\n",
    "#首先进行排序，如果从小到大排序，argsort参数是直接factorData，如果从大到小排序，使用-factorData。\n",
    "factorData = np.random.rand(10)\n",
    "xaxislabel = np.array([str(i) for i in range(10)])\n",
    "x = xaxislabel[np.argsort(-factorData)]\n",
    "y = factorData[np.argsort(-factorData)] \n",
    "\n",
    "plt.xticks(np.arange(len(xaxislabel)), x, rotation=270, fontsize =18)#xticks旋转270度显示\n",
    "plt.bar(np.arange(len(xaxislabel)), y)\n",
    "#不要直接画plt（x,y)，直接这样画的话横轴的sticklabel的顺序就是根据它的alphabet顺序。\n",
    "#所以分别对应一个np.arrange画。\n",
    "\n",
    "plt.ylabel('y轴名称', fontsize =18)\n",
    "plt.xlabel('x轴名称', fontsize =18)\n",
    "plt.title('图片标题', fontsize =18)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name_list = ['Monday','Tuesday','Friday','Sunday']\n",
    "num_list = [1.5,0.6,7.8,6]\n",
    "\n",
    "m=dict(zip(name_list,num_list))\n",
    "a=sorted(m.items(),key=lambda x: x[1],reverse=True)\n",
    "for i in range(len(a)):\n",
    "    plt.bar(a[i][0],a[i][1])\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "data=pd.read_excel(r\"E:\\个人贷款客户信息表.xlsx\",usecols=[1,4,6,7,8,9,10,11,12])\n",
    "\n",
    "data=data[data[\"合同生效日\"]>datetime(2018,12,31)]\n",
    "\n",
    "data=pd.concat([data1,data2,data3],ignore_index=True) # ignore_index重置行索引\n",
    "\n",
    "f['品牌'] = df['品牌'] .str.replace('[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。‘ ？、~@#￥%……&*（）]+','')\n",
    "\n",
    "df['prod_detail']=df['prod_detail'].str.extract('{\"净含量\":\"(.*?)\"}')\n",
    "               \n",
    "df['product']=df['product'].str.contains('京|津|浙')\n",
    "\n",
    "def func(str1,str2 ):\n",
    "      if str1 in str2:\n",
    "         return 1\n",
    "      return 0\n",
    "df['ff']=df[['product','mm']].apply(lambda x: func(x['mm'], x['product']),axis=1)\n",
    "               \n",
    "# numpy.ravel() vs numpy.flatten()\n",
    "# 两者所要实现的功能是一致的（将多维数组降为一维），两者的区别在于返回拷贝（copy）还是返回视图（view），\n",
    "# numpy.flatten()返回一份拷贝，对拷贝所做的修改不会影响（reflects）原始矩阵，\n",
    "# 而numpy.ravel()返回的是视图（view，也颇有几分C/C++引用reference的意味），会影响（reflects）原始矩阵。               \n",
    "\n",
    "# 列属性为object修改为数值型\n",
    "cols = data.columns[data.dtypes.eq(object)]\n",
    "data[cols] = data[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(np.linspace(1,10, num=10)) # 等差数列\n",
    "print(np.logspace(1,10, num=10)) # 等比数列\n",
    "               \n",
    "X = np.array(new_data.iloc[:, new_data.columns != 'Class']) # 选取特征列数据\n",
    "y = np.array(new_data.iloc[:, new_data.columns == 'Class']) # 选取类别label         \n",
    "               \n",
    "df = pd.read_csv(\"haiwang.csv\",sep=\",\",header=None,names=[\"nickName\",\"cityName\",\"content\"])\n",
    "# names等效于header = None并给数据加了一个你喜欢的列名\n",
    "data[\"content_length\"] = data[\"content\"].apply(len)\n",
    "\n",
    "# pandas 读取txt文本               \n",
    "import pandas as pd\n",
    "data = pd.read_table('test.txt', ,header=None, encoding='gb2312', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件合并\n",
    "***********************************************************************************************************************************\n",
    "file_list = os.listdir(file_path)\n",
    "print('开始进行合并处理：...\\n')\n",
    "df = pd.DataFrame()\n",
    "for file_name in file_list:\n",
    "    if os.path.splitext(file_name)[1] == '.csv':\n",
    "        print(file_name,'-->正在进行合并处理...',)\n",
    "        open_csv_path=file_path+file_name\n",
    "        df1 = pd.read_csv(open_c sv_path,skiprows=6,engine='python',error_bad_lines=False,low_memory=True,encoding='utf-8')\n",
    "        df =pd.concat([df,df1],axis=0,ignore_index=True) # append\n",
    "        print(file_name,'--->已完成合并!!!')\n",
    "    else:\n",
    "        print(file_name,'-->不是CSV文件!!!')\n",
    "df.to_csv(file_path+outfile_name,encoding=\"GBK\",index=False)\n",
    "print(outfile_name+'已输出！！！')\n",
    "\n",
    "读取指定列：\n",
    "usecols1=['网管中网元名称','所属地市','所属区县','覆盖场景','所属厂商']\n",
    "df=pd.read_csv(file_name,engine='c',error_bad_lines=False,low_memory=False,encoding='gb18030',usecols=usecols1)\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "l= []\n",
    "n = 0\n",
    "for file in os.walk(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\code\\BDsql'):\n",
    "    for table in file[2]:\n",
    "        path = file[0] + '/' + table\n",
    "        data = pd.read_excel(path,header = None ,encoding = 'utf-8')\n",
    "        n = n+1\n",
    "        l.append(data)\n",
    "\n",
    "        print('第'+str(n)+'个表格已提取')\n",
    "\n",
    "data_result = pd.concat(l,ignore_index=True)\n",
    "data_result.to_csv('C:/Users/Nick/Desktop/data_result.csv',index = False,encoding='utf-8-sig')\n",
    "\n",
    "t2 = time.time()\n",
    "t = t2-t1\n",
    "t = round(t,2)\n",
    "print('用时'+str(t)+'秒')\n",
    "print('完成')\n",
    "***********************************************************************************************************************************\n",
    "resou = pd.DataFrame(columns=['datetime','title','searchCount'])\n",
    "\n",
    "for i in range(1,20):\n",
    "    url= 'https://www.enlightent.cn/research/top/getWeiboRankSearch.do?keyword=王思聪&from='+ str(i) +'&t=395201742&type=realTimeHotSearchList'\n",
    "    html = requests.get(url=url, cookies=cookie, headers=header).content\n",
    "    data = json.loads(html.decode('utf-8'))\n",
    "    for j in range(20): #一页20个\n",
    "        resou = resou.append({'datetime':stampToTime(data['rows'][j]['updateTime']),\n",
    "                'title':data['rows'][j]['keywords'],'searchCount':data['rows'][j]['searchNums'],\n",
    "                              },ignore_index=True)\n",
    "\n",
    "resou.to_csv(\"resou.csv\", index_label=\"index_label\",encoding='utf-8-sig')\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "data = []\n",
    "time_start = time.time()  # 开始计时\n",
    "i = 0;\n",
    "for row in rows:\n",
    "    prod_id = row['prod_id']\n",
    "    final_Prod, final_label = regex(row)\n",
    "    data.append([prod_id, final_Prod, final_label])\n",
    "    i=i+1\n",
    "    if (i% 1000 == 0):\n",
    "        print(i)\n",
    "result = pd.DataFrame(data, columns=['prod_id', 'final_prod', 'final_label'])\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "os.chdir(r'D:\\360MoveData\\Users\\Administrator\\Desktop\\Bearing1_1')\n",
    "table=os.listdir()\n",
    "all=len(table)\n",
    "num=1\n",
    "result1=pd.DataFrame()\n",
    "for temp_table in table:\n",
    "    df=pd.read_csv(temp_table,header=None)\n",
    "    df['均方根']=math.sqrt(sum([x ** 2 for x in df.loc[:,4]]) / len(df.loc[:,4]))\n",
    "    df['均值']=df.loc[:,4].mean()\n",
    "    rms=df['均方根'][0]\n",
    "    avg=df['均值'][0]\n",
    "    table_name=temp_table\n",
    "    life=(all-num)/all\n",
    "    extremum=max(df.loc[:,4])-min(df.loc[:,4])\n",
    "    waveform_index=rms/abs(avg)\n",
    "    pulse_index=max(df.loc[:,4])/abs(avg)\n",
    "    kurtosis_value=df.loc[:,4].kurt()\n",
    "    peak_value=max(df.loc[:,4])/rms\n",
    "    num=num+1\n",
    "    result=pd.DataFrame({'均方根':[rms],'均值':avg,'表名':table_name,'剩余寿命':life,'极值':extremum, \n",
    "                         '波形指标':waveform_index,'脉冲指标':pulse_index,'峭度指标':kurtosis_value,'峰值':peak_value,\n",
    "                        '裕度指标':margin_index})\n",
    "    result1=pd.concat([result1,result],ignore_index=False)\n",
    "print(result1.reset_index(drop=True))\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir_path=r'E:\\PDF\\python_pdf'\n",
    "def cleanup(cleanup_dir_path):\n",
    "    ext_data = {}\n",
    "    for file in os.listdir(cleanup_dir_path):\n",
    "        file_ext = os.path.splitext(file)\n",
    "        file_ext = file_ext[1][1:]\n",
    "        if file_ext not in ext_data:\n",
    "            ext_data[file_ext] = []\n",
    "        ext_data[file_ext].append(file)\n",
    "\n",
    "    for ext, files in ext_data.items():\n",
    "        ext_dir = f'{cleanup_dir_path}{ext}'\n",
    "        if not os.path.isdir(ext_dir):\n",
    "            os.mkdir(ext_dir)\n",
    "        for file in files:\n",
    "            old_file_path = f'{cleanup_dir_path}\\\\{file}'\n",
    "            new_file_path = f'{ext_dir}\\\\{file}'\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    if len(sys.argv) != 2:\n",
    "        raise Exception(\"输入要清理的目录\")\n",
    "    dir_path = sys.argv[1] + '\\\\'\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise Exception(f\"{dir_path}不是目录\")\n",
    "    cleanup(dir_path)\n",
    "    print(\"文件整理完成\")\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import time\n",
    "\n",
    "#开始时间\n",
    "start = time.time()\n",
    "#存储汇总的结果\n",
    "result = pd.DataFrame()\n",
    "#循环遍历表格名称\n",
    "for name in os.listdir():\n",
    "    df = pd.read_excel(name)\n",
    "    #计算销售额字段\n",
    "    df['销售额'] = df['访客数'] * df['转化率'] * df['客单价']\n",
    "    #按品牌对细分行业销售额进行汇总\n",
    "    df_sum = df.groupby('品牌')['销售额'].sum().reset_index()\n",
    "    df_sum['类目'] = name.replace('.xlsx','')\n",
    "    result = pd.concat([result,df_sum])\n",
    "\n",
    "#对最终结果按销售额进行排序\n",
    "final = result.groupby('品牌')['销售额'].sum().reset_index().sort_values('销售额',ascending = False)\n",
    "\n",
    "#结束时间\n",
    "end = time.time()\n",
    "print('用Python操作所花费时间：{} s'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas读取工作簿里面的所有工作表\n",
    "import pandas as pd\n",
    "\n",
    "f = pd.ExcelFile('./data/meal_order_detail.xlsx')\n",
    "f.sheet_names # 获取工作表名称\n",
    "data = pd.DataFrame()\n",
    "for i in f.sheet_names:\n",
    "    d = pd.read_excel('./data/meal_order_detail.xlsx', sheetname=i)\n",
    "    data = pd.concat([data, d])\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "# 将文件导出到一个excel的多个sheet\n",
    "writer=pd.ExcelWriter(excelpath,engine=\"xlsxwriter\",options={'strings_to_urls': False})\n",
    "df1.to_excel(writer,sheet_name='表1')\n",
    "df2.to_excel(writer,sheet_name='表2')\n",
    "df3.to_excel(writer,sheet_name='表3')\n",
    "writer.save()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "# stack()是将表格型数据转化为树形数据(是在保持行索引不变的前提下，将列索引也变成行索引)\n",
    "# unstack()是将树形数据转化为表格型数据\n",
    "\n",
    "# 宽表转长表：\n",
    "df.set_index([\"Company\",\"Name\"]).stack().reset_index()\n",
    "\n",
    "# 长表转宽表：\n",
    "df.pivot_table(index=[\"Company\",\"Name\"],columns=\"Year\",values=\"Sale\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产地解析地域下沉\n",
    "import pandas as pd\n",
    "import os\n",
    "import jieba\n",
    "import time\n",
    "import records\n",
    "from numba import jit\n",
    "\n",
    "os.chdir(r'D:\\Jupyter\\映潮数据\\产地解析')\n",
    "start_time=time.time()\n",
    "df= pd.read_excel(r\"area2017.xlsx\",sheet_name=\"Sheet1\")\n",
    "\n",
    "map_area= pd.read_excel(r\"map_area.xlsx\",sheet_name=\"Sheet1\")\n",
    "\n",
    "\n",
    "from collections import defaultdict \n",
    "area_map = defaultdict(list)\n",
    "for i in range(df.shape[0]):\n",
    "    area_map[df['areaid'][i]].append(df['area'][i])\n",
    "\n",
    "\n",
    "db = records.Database('postgresql://yanghai:NlPtI38V2iZv@pg.sunsharp.cn/warehouse')\n",
    "select_table = 'mining_testdb.cd_taobao_product20191213 '\n",
    "sql = \" SELECT prod_id,prod_name,produce_first_addr,produce_second_addr,produce_third_addr,produce_first_areaid,\\\n",
    "       produce_second_areaid,produce_third_areaid,url  FROM {} limit 60000  \".format(select_table)\n",
    "rows = db.query(sql)\n",
    "rows = rows.all(as_dict=True)\n",
    "rows=pd.DataFrame(rows) \n",
    "\n",
    "\n",
    "# 加载自定义词库\n",
    "jieba.load_userdict(r'all_words1213.txt')\n",
    "rows['fenci']=rows['prod_name'].apply(lambda x: jieba.lcut(str(x)))\n",
    "\n",
    "\n",
    "def write_to_table(df, table_name, if_exists='fail'):\n",
    "    from sqlalchemy import create_engine\n",
    "    import io\n",
    "    db_engine = create_engine('postgresql://yanghai:NlPtI38V2iZv@pg.sunsharp.cn/warehouse')\n",
    "    string_data_io = io.StringIO()\n",
    "    df.to_csv(string_data_io, sep='|', index=False)\n",
    "    pd_sql_engine = pd.io.sql.pandasSQL_builder(db_engine)\n",
    "    table = pd.io.sql.SQLTable(table_name, pd_sql_engine, frame=df,\n",
    "                                   index=False, if_exists=if_exists,schema = 'mining_testdb')\n",
    "    table.create()\n",
    "    string_data_io.seek(0)\n",
    "    string_data_io.readline()\n",
    "    with db_engine.connect() as connection:\n",
    "        with connection.connection.cursor() as cursor:\n",
    "            copy_cmd = \"COPY mining_testdb.%s FROM STDIN HEADER DELIMITER '|' CSV\" %table_name\n",
    "            cursor.copy_expert(copy_cmd, string_data_io)\n",
    "        connection.connection.commit()\n",
    "\n",
    "# @jit        \n",
    "def get_dictarea(area_map, x):\n",
    "    if x is not None:\n",
    "        x=[ areaid for areaid, area_addr in area_map.items() for m  in area_addr  for n in x if m==n]\n",
    "    return x\n",
    "\n",
    "\n",
    "data=[]\n",
    "for index,row in rows.iterrows():\n",
    "       m=[i  if i in df['area'].values else None for i in row['fenci']]\n",
    "       n=[f for f in m if f is not None ]\n",
    "       n1=pd.Series(n).unique().tolist()\n",
    "       n2=get_dictarea(area_map, n1)\n",
    "       data.append(n2)\n",
    "        \n",
    "rows['out']=data\n",
    "\n",
    "del rows['fenci']\n",
    "rows=rows[rows['out'].notnull()]\n",
    "\n",
    "\n",
    "# @jit\n",
    "def fun1(v1,v2,v3,out):\n",
    "    for i in out:\n",
    "        if v2 is None  and str(int(v1))==str(i)[:2] and i> v1:\n",
    "            return  i\n",
    "        elif v2 is not None  and  str(v3)=='nan' and str(int(v2))==str(i)[:4] and i> v2:\n",
    "            return  i\n",
    "          \n",
    "rows['out']=rows.apply(lambda row: fun1(row['produce_first_areaid'],row['produce_second_areaid'],row['produce_third_areaid'],row['out']),axis=1)\n",
    "rows=rows[rows['out'].notnull()].reset_index()\n",
    "\n",
    "\n",
    "for i in range(rows.shape[0]):\n",
    "    if len(str(int(rows.loc[i,'out']))) == 6: \n",
    "        rows.loc[i,'produce_second_areaid']=str(rows.loc[i,'out'])[:4]\n",
    "        rows.loc[i,'produce_third_areaid']=rows.loc[i,'out']\n",
    "    elif len(str(int(rows.loc[i,'out']))) == 4:\n",
    "        rows.loc[i,'produce_second_areaid']=rows.loc[i,'out']\n",
    "              \n",
    "del rows['out']  \n",
    "\n",
    "\n",
    "rows['produce_second_areaid'] = pd.to_numeric(rows['produce_second_areaid'], errors='coerce')\n",
    "rows['produce_third_areaid'] = pd.to_numeric(rows['produce_third_areaid'], errors='coerce')\n",
    "map_area['produce_second_areaid'] = pd.to_numeric(map_area['produce_second_areaid'], errors='coerce')\n",
    "map_area['produce_third_areaid'] = pd.to_numeric(map_area['produce_third_areaid'], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "rows= pd.merge(rows,map_area[['produce_second_areaid','produce_second_addr']].drop_duplicates(),how='left',on = 'produce_second_areaid')    \n",
    "rows= pd.merge(rows,map_area[['produce_third_areaid','produce_third_addr']],how='left',on = 'produce_third_areaid')    \n",
    "\n",
    "\n",
    "del rows['produce_second_addr_x']\n",
    "del rows['produce_third_addr_x']\n",
    "rows.rename(columns={'produce_second_addr_y':'produce_second_addr','produce_third_addr_y':'produce_third_addr'},inplace=True)\n",
    "\n",
    "  \n",
    "    \n",
    "insert_table = 'cdresult_{}'.format(time.strftime('%Y%m%d%H%M%S'))   \n",
    "# write_to_table(result,insert_table)\n",
    "   \n",
    "\n",
    "rows.to_csv(r'cdresult_{}.csv'.format(time.strftime('%Y%m%d%H%M%S')),encoding='utf_8_sig',index=False)\n",
    "end_time=time.time()\n",
    "print('共花费时间： {:.2f} s'.format(end_time-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.DataFrame({\"xs\":[1,5,2,8,1], \"ys\":[4,2,1,9,6]})\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "df.plot.scatter(\"xs\", \"ys\", color = \"black\", marker = \"x\")\n",
    "\n",
    "df = pd.DataFrame({\"productivity\":[5,2,3,1,4,5,6,7,8,3,4,8,9],\n",
    "                   \"hours_in\"    :[1,9,6,5,3,9,2,9,1,7,4,2,2],\n",
    "                   \"happiness\"   :[2,1,3,2,3,1,2,3,1,2,2,1,3],\n",
    "                   \"caffienated\" :[0,0,1,1,0,0,0,0,1,1,0,1,0]})\n",
    "\n",
    "df.plot.scatter(\"hours_in\", \"productivity\", s = df.happiness * 100, c = df.caffienated)\n",
    "\n",
    "df = pd.DataFrame({\"revenue\":[57,68,63,71,72,90,80,62,59,51,47,52],\n",
    "                   \"advertising\":[2.1,1.9,2.7,3.0,3.6,3.2,2.7,2.4,1.8,1.6,1.3,1.9],\n",
    "                   \"month\":range(12)})\n",
    "\n",
    "ax = df.plot.bar(\"month\", \"revenue\", color = \"green\")\n",
    "df.plot.line(\"month\", \"advertising\", secondary_y = True, ax = ax)\n",
    "ax.set_xlim((-1,12));\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "import networkx as nx\n",
    "\n",
    "# 建network\n",
    "G = nx.Graph()\n",
    "edges = list(zip(related_df['title'], related_df['related']))\n",
    "G.add_edges_from(edges)\n",
    "# 画图\n",
    "plt.figure(figsize=(25, 25))\n",
    "nx.draw(G, with_labels=False)\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.countplot(x='CabinCat', hue='Survived',data=df)\n",
    "plt.show()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "from scipy.stats import *\n",
    "sns.distplot(x,hist=False,fit=norm) #拟合标准正态分布\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "https://github.com/fengdu78/machine_learning_beginner/tree/master/seaborn\n",
    "seaborn一共有5个大类21种图，分别是：\n",
    "Relational plots 关系类图表\n",
    "relplot() 关系类图表的接口，其实是下面两种图的集成，通过指定kind参数可以画出下面的两种图\n",
    "scatterplot() 散点图\n",
    "lineplot() 折线图\n",
    "Categorical plots 分类图表\n",
    "catplot() 分类图表的接口，其实是下面八种图表的集成，通过指定kind参数可以画出下面的八种图\n",
    "stripplot() 分类散点图\n",
    "swarmplot() 能够显示分布密度的分类散点图\n",
    "boxplot() 箱图\n",
    "violinplot() 小提琴图\n",
    "boxenplot() 增强箱图\n",
    "pointplot() 点图\n",
    "barplot() 条形图\n",
    "countplot() 计数图\n",
    "Distribution plot 分布图\n",
    "jointplot() 双变量关系图\n",
    "pairplot() 变量关系组图\n",
    "distplot() 直方图，质量估计图\n",
    "kdeplot() 核函数密度估计图\n",
    "rugplot() 将数组中的数据点绘制为轴上的数据\n",
    "Regression plots 回归图\n",
    "lmplot() 回归模型图\n",
    "regplot() 线性回归图\n",
    "residplot() 线性回归残差图\n",
    "Matrix plots 矩阵图\n",
    "heatmap() 热力图\n",
    "clustermap() 聚集图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 客户对接链接验证\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "os.chdir(r'D:\\360MoveData\\Users\\Administrator\\Desktop')\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "# 禁用安全请求警告\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "#设置重连次数\n",
    "requests.adapters.DEFAULT_RETRIES = 5\n",
    "# 设置连接活跃状态为False\n",
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "\n",
    "\n",
    "def fun(url):\n",
    "    headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',\n",
    "    'Connection':'close'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url,headers=headers,timeout=10,allow_redirects=False,verify=False)\n",
    "        res=response.text\n",
    "        if response.status_code == 200:\n",
    "#             res=response.text.replace('\\r','').replace('\\n','').replace('\\t','')\n",
    "            if url.find('jd.com')!=-1:\n",
    "                shop_id=re.findall('https://mall.jd.com/index-(\\d+).html',url)[0]\n",
    "                shop_name =re.findall('<title>(.*?)-.*?</title>',res)[0].strip()\n",
    "                status=1\n",
    "            elif  url.find('taobao.com')!=-1 or url.find('tmall.com')!=-1:\n",
    "                shop_id=re.findall('shopId=.*?;userId=(.*?)\"',res)[0]\n",
    "                shop_name =re.findall('<title>.*?-(.*?)-.*?</title>',res)[0]            \n",
    "                status=1\n",
    "            elif  url.find('yangkeduo.com')!=-1 :\n",
    "                shop_id=re.findall('mall_id=(\\d+)',url)[0]\n",
    "                shop_name =None     \n",
    "                status=1\n",
    "            elif  url.find('tyfo.com')!=-1 :\n",
    "                shop_id=re.findall('shop/goShop\\?shopId=(\\d+)',res)[0] \n",
    "                shop_name =re.findall('<title>(.*?)_天虎云商</title>',res)[0]  \n",
    "                status=1\n",
    "            else:\n",
    "                shop_id=None\n",
    "                shop_name=None\n",
    "                status=1\n",
    "            return shop_id,shop_name,status\n",
    "        return  None,None,0\n",
    "    except  Exception as e:\n",
    "            print('异常1',e)\n",
    "            return  None,None,-1\n",
    "\n",
    "df1= pd.read_excel(r\"temp_table.xlsx\")\n",
    "data=[]\n",
    "for url in df1['url']:\n",
    "    try:\n",
    "        shop_id,shop_name,status=fun(url)\n",
    "        data.append([shop_id,shop_name,url,status])\n",
    "    except  Exception as e:\n",
    "        print('异常2',e)\n",
    "    continue\n",
    "df2=pd.DataFrame(data,columns=['shop_id', 'shop_name','url', 'status'])\n",
    "#df2.to_excel(r\"C:\\Users\\Administrator\\Desktop\\爬取结果.xlsx\",index=True)\n",
    "writer = pd.ExcelWriter(r\"结果.xlsx\",engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "df2.to_excel(writer, sheet_name='Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "# 验证店铺状态\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "os.chdir(r'F:\\360MoveData\\Users\\Administrator\\Desktop')\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "# 禁用安全请求警告\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "#设置重连次数\n",
    "requests.adapters.DEFAULT_RETRIES = 5\n",
    "# 设置连接活跃状态为False\n",
    "s = requests.session()\n",
    "s.keep_alive = False\n",
    "\n",
    "\n",
    "def fun(url):\n",
    "    headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',\n",
    "    'Connection':'close'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url,headers=headers,timeout=20,allow_redirects=False,verify=False) \n",
    "#         response = requests.get(url,headers=headers,timeout=20,allow_redirects=False)\n",
    "        if response.status_code == 200:\n",
    "            return 1\n",
    "        elif response.status_code == 301 and  (url.find('taobao.com')!=-1 or  url.find('hc360.com')!=-1 or  url.find('tuniu.com')!=-1 or  url.find('elong.com')!=-1  ):\n",
    "            return 1\n",
    "#         elif response.status_code == 307 and  url.find('hotels.ctrip.com')!=-1 :\n",
    "#             return 1\n",
    "#         elif response.status_code == 302 and  url.find('touch.qunar.com')!=-1 :\n",
    "#             return 1\n",
    "        elif response.status_code == 302 and  (url.find('jd.com')!=-1 or url.find(' zbj.com')!=-1 or url.find('meituan.com')!=-1) :  \n",
    "             return 0\n",
    "        elif response.status_code == 403 :  \n",
    "             return 0 \n",
    "        \n",
    "                                               \n",
    "        else:\n",
    "            return  response.status_code\n",
    "    except  Exception as e:\n",
    "            print('异常1',e)\n",
    "            return  -1\n",
    "\n",
    "n=0       \n",
    "start_time=time.time()\n",
    "df= pd.read_excel(r\"陕西口罩网商.xlsx\")\n",
    "data=[]\n",
    "data_len=len(df['url'])\n",
    "for url in df['url']:\n",
    "    try:\n",
    "        status=fun(url)\n",
    "        n=n+1\n",
    "        data.append(status)\n",
    "        if n%200==0:\n",
    "            print('进度  {:.2f}%'.format(n/data_len*100))\n",
    "            print('待刷新  {}'.format(data_len-n))\n",
    "    except  Exception as e:\n",
    "        print('异常2',e)\n",
    "    continue\n",
    "    \n",
    "df[ 'status']=data\n",
    "\n",
    "writer = pd.ExcelWriter(r\"结果20200210.xlsx\",engine='xlsxwriter',options={'strings_to_urls': False})\n",
    "df.to_excel(writer, sheet_name='Sheet1',index=False)\n",
    "writer.save()\n",
    "\n",
    "end_time=time.time()\n",
    "print('共花费时间： {:.2f} s'.format(end_time-start_time))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'考试':['一模','二模','一模','二模','一模','二模'],\n",
    "        '姓名':['张三','张三','李四','李四','王五','王五'],\n",
    "        '语文':[78,75,68,72,80,82],\n",
    "        '数学':[90,95,78,76,100,92],\n",
    "        '英语':[85,82,78,76,86,93]}\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "# 方法一\n",
    "# 一定要深刻体会groupby后加的字段的不同\n",
    "delta = df.groupby('姓名')['考试','语文','数学','英语'].last() - df.groupby('姓名')['语文','数学','英语'].first()\n",
    "# 重设索引，使姓名列恢复列字段\n",
    "delta.reset_index(inplace = True)\n",
    "# 填充为对比，满足需求的每一个小细节\n",
    "delta.fillna('对比',inplace=True)\n",
    "# 输出瞧一瞧\n",
    "delta\n",
    "# 这种方式是可以设置ignore_index = True\n",
    "df.append(delta,ignore_index = True,sort = False).sort_values('姓名').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# 方法二\n",
    "delta = df.groupby('姓名').diff().dropna()\n",
    "delta\n",
    "# 这种方式必须设置ignore_index = False，否则在索引排序时就会匹配不到结果\n",
    "df.append(delta,ignore_index = False,sort = False).sort_index().fillna({'考试':'对比'}).fillna(method = 'ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.   resample按时间聚合\n",
    "# W星期,M月,Q季度,QS季度的开始第一天开始,A年,10A十年,10AS十年聚合日期第一天开始 H T S\n",
    "#对去重后的数据按照天进行重新采样\n",
    "# 首先要把索引变成时间\n",
    "df.index = pd.DatetimeIndex(df['createTime'])\n",
    "# 然后对其按照每天重新采样\n",
    "df.D = df.content.resample('D').count()\n",
    "\n",
    "df.D.plot(color='r',marker='D')\n",
    "plt.title('每天评论数据')\n",
    "plt.savefig('每天评论数据.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "df.H = df.content.resample('H').count()\n",
    "df.H.plot(color='g',marker='D',xticks=df.H.index)\n",
    "plt.title('每小时评论数据')\n",
    "plt.savefig('每小时评论数据.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "df.v = df.content.resample('T').count()\n",
    "df.v.plot(color='b',marker='D',xticks=df.v.index)\n",
    "plt.show()\n",
    "\n",
    "for x, y in zip(np.arange(len(df1.index)),df1.values):\n",
    "    plt.text(x, y, '%.0f' % y, ha='center', va='bottom')\n",
    "\n",
    "# 2.   resample按时间聚合\n",
    "df.date = pd.to_datetime(df.date,format=\"%Y%m%d\")\n",
    "df.set_index('date',drop=True)\n",
    "\n",
    "# 常用日期处理方法\n",
    "dates = pd.to_datetime(pd.Series(['1989-8-18 13:14:55','1995-2-16']), format = '%Y-%m-%d %H:%M:%S')\n",
    "print('返回日期值：\\n',dates.dt.date)\n",
    "print('返回季度：\\n',dates.dt.quarter)\n",
    "print('返回几点钟：\\n',dates.dt.hour)\n",
    "print('返回年中的天：\\n',dates.dt.dayofyear)\n",
    "print('返回年中的周：\\n',dates.dt.weekofyear)\n",
    "print('返回星期几的名称：\\n',dates.dt.weekday_name)\n",
    "print('返回月份的天数：\\n',dates.dt.days_in_month)\n",
    "\n",
    "datas['dates'] = pd.to_datetime(datas['date'],format='%Y年%m月')\n",
    "data['current_dt']=data['current_dt'].apply(lambda x: x.strftime('%Y-%m-%d  %H:%M:%S'))\n",
    "data['str_ts'] = data['ts'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 第一种\n",
    "matplotlib.rcParams['font.family']='SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# 第二种\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "***********************************************************************************************************************************\n",
    "# 数据去重和名称去重\n",
    "data=data.T.drop_duplicates().T \n",
    "data=data.loc[:, ~data.columns.duplicated()]\n",
    "\n",
    "for i in data.columns:\n",
    "    if '必修课' in i:\n",
    "        bx.append(i)\n",
    "    elif '公共选修课' in i:\n",
    "        xx.append(i)\n",
    "\n",
    "sns.pairplot(data, vars=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], hue='species',kind=\"reg\")\n",
    "\n",
    "data.drop(columns=['姓名', '学号', '获得学分', '序号'],inplace=True)\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\题1数据')\n",
    "for temp_table  in os.listdir():\n",
    "    f = pd.ExcelFile(temp_table)\n",
    "    data = pd.DataFrame()\n",
    "    for i in f.sheet_names:\n",
    "        d = pd.read_excel(temp_table, sheetname=i)\n",
    "        data = pd.concat([data, d])   \n",
    "        \n",
    "data.drop_duplicates(inplace=True)    \n",
    "    \n",
    "data.to_csv(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\1.csv',encoding='utf_8_sig')\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\题2数据')\n",
    "data=pd.read_csv(r'题2数据.csv',encoding='GB18030')\n",
    "    \n",
    "data['交易卡号']=data.apply(lambda x: x['交易账号'] if pd.isnull(x['交易卡号']) else x['交易卡号'],axis=1)\n",
    "\n",
    "data=data[data['交易金额']!=0]   \n",
    "\n",
    "# 判断空值\n",
    "# data[\"对手卡号\"].fillna(data[\"交易卡号\"]+\"&用途&\"+data[\"摘要\"],inplace = True)\n",
    "# data['对手卡号']=data.apply(lambda x:  str(x['交易账号']) + '&用途：&' + str(x['摘要']) if pd.isna(x['对手卡号']) else x['对手卡号'],axis=1)\n",
    "data['对手卡号']=data.apply(lambda x:  str(x['交易账号']) + '&用途：&' + str(x['摘要']) if pd.isnull(x['对手卡号']) else x['对手卡号'],axis=1)\n",
    "\n",
    "\n",
    "data.to_csv(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\题2数据.csv',encoding='GB18030')\n",
    "***********************************************************************************************************************************\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\3')\n",
    "n=0\n",
    "data_result=pd.DataFrame()\n",
    "for temp_table  in os.listdir():\n",
    "    data = pd.read_excel(temp_table,encoding = 'utf-8')\n",
    "    data['酒店名'] = temp_table.replace('.xlsx','')\n",
    "    n = n+1\n",
    "    data_result=pd.concat([data,data_result])\n",
    "    print('第'+str(n)+'个表格已提取')\n",
    "    \n",
    "data_result.to_csv(r'F:\\360MoveData\\Users\\Administrator\\Desktop\\结果.csv',encoding='utf_8_sig')\n",
    "***********************************************************************************************************************************\n",
    "# 第一种\n",
    "df=pd.read_excel(r'结果.xlsx',sheet_name=0,index_col=0,parse_dates=['评论时间'],,usecols=[1,4,6,7,8,9,10,11,12],dtype={'date': np.str_, 'close': np.float})\n",
    "# 第二种\n",
    "# names等效于header = None并给数据加了一个你喜欢的列名\n",
    "df = pd.read_csv(\"结果.csv\",sep=\",\",header=None,names=[\"nickName\",\"cityName\",\"content\"])\n",
    "\n",
    "# 第一种\n",
    "data.to_csv(outputfile,index = False, header = False, encoding = 'utf_8_sig')\n",
    "# 第二种\n",
    "data.to_csv(outputfile, index=True, index_label='name', header=['count'])\n",
    "***********************************************************************************************************************************\n",
    "pd.cut(df['去过城市数量'],np.arange(0,80,10)).value_counts().sort_values(ascending=True).plot(kind='barh')\n",
    "sns.countplot(x=df['出行方式'],hue=df['酒店名'])\n",
    "sns.heatmap(data.corr(), vmax=1, square=False, annot=True, linewidth=1)\n",
    "sns.lineplot(x='year', y='Aqi', data=df)\n",
    "sns.barplot(x='season', y='Aqi', hue='year', data=df)\n",
    "sns.regplot(x='pm10', y='Aqi', data=df)\n",
    "sns.scatterplot(x='评分', y='累记出游人数', data=df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bin_edges = [0, 50, 100, 150, 200, 300, 1210] \n",
    "bin_names = ['优级', '良好', '轻度污染', '中度污染', '重度污染', '重污染']\n",
    "df['空气质量'] = pd.cut(df['Aqi'], bin_edges, labels=bin_names)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.subplot(2,4,1)\n",
    "df['Aqi'].plot(kind='box')\n",
    "plt.subplot(2,4,2)\n",
    "df['pm2.5'].plot(kind='box')\n",
    "\n",
    "\n",
    "\n",
    "list(filter(lambda x:x>0.66,emotions))\n",
    "df.rename(columns={'city': 'cityname'}, inplace=True)\n",
    "\n",
    "\n",
    "seasons = {12: 'Winter',\n",
    "           1: 'Winter',\n",
    "           2: 'Winter',\n",
    "           3: 'Spring',\n",
    "           4: 'Spring',\n",
    "           5: 'Spring',\n",
    "           6: 'Summer',\n",
    "           7: 'Summer',\n",
    "           8: 'Summer',\n",
    "           9: 'Autumn',\n",
    "           10: 'Autumn',\n",
    "           11: 'Autumn' } \n",
    "# df['season'] = df['date'].apply(lambda x : x.month)  日期类型直接x.month\n",
    "df['season'] = df['date'].apply(lambda x : seasons[x.month])\n",
    "***********************************************************************************************************************************\n",
    "df[['Aqi']]=df[['Aqi']].apply(lambda x:x-x.mean() )\n",
    "\n",
    "# AQI、pm2_5、pm10、so2、no2、co、o3目前存在0值，可理解为该部分数据缺失，用对应城市的平均值进行填充。\n",
    "df[['Aqi','pm2.5','pm10','so2','co','no2','o3']] = df[['Aqi','pm2.5','pm10','so2','co','no2','o3']].replace(0, np.nan)\n",
    "# 将0值替换后缺失值的数量\n",
    "df.isnull().sum() \n",
    "\n",
    "# 第一种填充方法\n",
    "# for循环计算每个城市污染物的平均值后替换NaN值\n",
    "for pollutant in['Aqi','pm2.5','pm10','so2','co','no2','o3']:\n",
    "    df.loc[df[pollutant].isnull(), pollutant] = df[pollutant].mean()\n",
    "\n",
    "# 第二种填充方法\n",
    "df[['Aqi','pm2.5','pm10','so2','co','no2','o3']].fillna(df[['Aqi','pm2.5','pm10','so2','co','no2','o3']].mean(),inplace=True) \n",
    "***********************************************************************************************************************************\n",
    "\n",
    "***********************************************************************************************************************************\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
